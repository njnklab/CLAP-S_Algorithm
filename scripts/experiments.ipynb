{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/a001/Documents/ZhengHaoyu/python/1_important/OCMN')\n",
    "import glob\n",
    "from utils.generator import Generator, ERGenerator, BAGenerator, SFGenerator\n",
    "from utils.utils import save_network, read_network, setup_logger, create_output_file\n",
    "from utils.plot import transform_graphs, visualize_networks_with_bipartite, visualize_networks_with_matching_and_bipartite\n",
    "from matching import Matching, MultiMatching\n",
    "import config\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [\"base\"] + [f\"overlap={overlap}\" for overlap in config.NETWORK_OVERLAP]\n",
    "\n",
    "def generate_and_save_networks(k_range={\"start\": 2, \"end\": 10, \"step\": 0.1}):\n",
    "    for k in tqdm(np.arange(k_range['start'], k_range['end'] + k_range[\"step\"], k_range[\"step\"])):\n",
    "        for n in config.NETWORK_NODES_LIST:\n",
    "            k = round(k, 2)\n",
    "            \n",
    "            er_generator = ERGenerator(n, k)\n",
    "            er_graphs = er_generator.generate_networks(len(networks), config.NETWORK_OVERLAP)\n",
    "            dir = f\"ER_n={n}_k={k}\"\n",
    "            os.makedirs(os.path.join(config.SYNTHETIC_NET_PATH, 'ER', dir), exist_ok=True)\n",
    "            for i in range(len(networks)):\n",
    "                save_network(er_graphs[i], os.path.join(config.SYNTHETIC_NET_PATH, 'ER', dir, f\"{networks[i]}.txt\"))\n",
    "            \n",
    "            ba_generator = SFGenerator(n, k)\n",
    "            ba_graphs = ba_generator.generate_networks(len(networks), config.NETWORK_OVERLAP)\n",
    "            dir = f\"BA_n={n}_k={k}\"\n",
    "            os.makedirs(os.path.join(config.SYNTHETIC_NET_PATH, 'BA', dir), exist_ok=True)\n",
    "            for i in range(len(networks)):\n",
    "                save_network(ba_graphs[i], os.path.join(config.SYNTHETIC_NET_PATH, 'BA', dir, f\"{networks[i]}.txt\"))\n",
    "\n",
    "generate_and_save_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同网络类型、不同平均度k、不同节点数N、重复实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_amount(\n",
    "    k_range={\"start\": 2, \"end\": 10, \"step\": 0.1},\n",
    "    n_list=config.NETWORK_NODES_LIST,\n",
    "    result_columns=[\n",
    "        \"network_type\", \"N\", \"<k>\", \"seq\", \n",
    "        \"MDS_1\", \"MDS_2\", \n",
    "        \"Diff_MDS_1\", \"Diff_MDS_2\", \"UDS_0\", \n",
    "        \"UDS_CLAPS\", \"UDS_RSU\", \"UDS_CLAPG\", \"UDS_ILP\", \n",
    "        \"clap_average_length\", \n",
    "        \"time_CLAPS\", \"time_RSU\", \"time_CLAPG\", \"time_ILP\"]\n",
    "):\n",
    "    output_file_name = create_output_file(result_columns, \"optimization_amount\")\n",
    "\n",
    "    for n in n_list:\n",
    "        print(f\"Processing n={n}...\")\n",
    "\n",
    "        # ER + ER; BA + BA; ER + BA\n",
    "        for network_type in [\"ER\", \"BA\", \"ER+BA\"]:\n",
    "            for k in tqdm(np.arange(k_range['start'], k_range['end'] + k_range[\"step\"], k_range[\"step\"])):\n",
    "                k = round(k, 2)\n",
    "                for seq in range(10):\n",
    "                    dir = f\"{network_type}_n={n}_k={k}\"\n",
    "                    matchings = []\n",
    "\n",
    "                    if \"+\" in network_type:\n",
    "                        graph_1 = read_network(os.path.join(config.SYNTHETIC_NET_PATH, \"ER\", f\"ER_n={n}_k={k}\", f\"base.txt\"), n)\n",
    "                        matching_1 = Matching(graph_1)\n",
    "                        matching_1.HK_algorithm()\n",
    "                        matchings.append(matching_1)\n",
    "                        graph_2 = read_network(os.path.join(config.SYNTHETIC_NET_PATH, \"BA\", f\"BA_n={n}_k={k}\", f\"base.txt\"), n)\n",
    "                        matching_2 = Matching(graph_2)\n",
    "                        matching_2.HK_algorithm()\n",
    "                        matchings.append(matching_2)\n",
    "                    else:\n",
    "                        for file in os.listdir(os.path.join(config.SYNTHETIC_NET_PATH, network_type, dir)):\n",
    "                            # 包含base或-1的文件名\n",
    "                            if \"base\" in file or \"-1\" in file:\n",
    "                                graph = read_network(os.path.join(config.SYNTHETIC_NET_PATH, network_type, dir, file), n)\n",
    "                                matching = Matching(graph)\n",
    "                                matching.HK_algorithm()\n",
    "                                matchings.append(matching)\n",
    "                    \n",
    "                    multi_matching = MultiMatching(matchings)\n",
    "                    multi_matching_rsuu = copy.deepcopy(multi_matching)\n",
    "                    multi_matching_glde = copy.deepcopy(multi_matching)\n",
    "                    multi_matching_ilp = copy.deepcopy(multi_matching)\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    pre_diff_mds_1_size, pre_diff_mds_2_size, pre_union_size, union_size, average_depth = multi_matching.CLAPS()\n",
    "                    end_time = time.time()\n",
    "                    time_clap_s = end_time - start_time\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    union_size_rsuu = multi_matching_rsuu.RSU()\n",
    "                    end_time = time.time()\n",
    "                    time_rsuu = end_time - start_time\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    union_size_glde = multi_matching_glde.CLAPG()\n",
    "                    end_time = time.time()\n",
    "                    time_glde = end_time - start_time\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    union_size_ilp = multi_matching_ilp.ILP_exact(budget_mode=\"auto\")\n",
    "                    end_time = time.time()\n",
    "                    time_ilp = end_time - start_time\n",
    "                    \n",
    "                    with open(output_file_name, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                        output_file.write(\",\".join([\n",
    "                            f\"{network_type}+{network_type}\" if \"+\" not in network_type else network_type, str(n), str(k), str(seq), \n",
    "                            str(len(matchings[0].driver_nodes)), str(len(matchings[1].driver_nodes)), \n",
    "                            str(pre_diff_mds_1_size), str(pre_diff_mds_2_size), str(pre_union_size), \n",
    "                            str(union_size), str(union_size_rsuu), str(union_size_glde), str(union_size_ilp), \n",
    "                            str(average_depth),\n",
    "                            str(time_clap_s),str(time_rsuu), str(time_glde), str(time_ilp)\n",
    "                        ]) + \"\\n\")\n",
    "\n",
    "optimization_amount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同网络类型、不同平均度k、不同网络重叠程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_proportion(\n",
    "    k_range={\"start\": 2, \"end\": 10, \"step\": 0.1},\n",
    "    n_list=config.NETWORK_NODES_LIST,\n",
    "    overlap_list=config.NETWORK_OVERLAP,\n",
    "    result_columns=[\n",
    "        \"network_type\", \"N\", \"<k>\", \"overlap\", \n",
    "        \"MDS_1\", \"MDS_2\", \n",
    "        \"Diff_MDS_1\", \"Diff_MDS_2\", \"UDS_0\", \n",
    "        \"UDS_CLAPS\", \"UDS_RSU\", \"UDS_CLAPG\", \"UDS_ILP\", \n",
    "        \"clap_average_length\", \n",
    "        \"time_CLAPS\", \"time_RSU\", \"time_CLAPG\", \"time_ILP\"]\n",
    "):\n",
    "    output_file_name = create_output_file(result_columns, \"optimization_proportion\")\n",
    "    \n",
    "    for n in n_list:\n",
    "        print(f\"Processing n={n}...\")\n",
    "        for network_type in [\"ER\", \"BA\"]:\n",
    "            print(f\"\\tProcessing {network_type}...\")\n",
    "            for overlap in overlap_list:\n",
    "                overlap = round(overlap, 3)\n",
    "                if overlap < 0:\n",
    "                    continue\n",
    "                for k in tqdm(np.arange(k_range['start'], k_range['end'] + k_range[\"step\"], k_range[\"step\"]), desc=f\"\\t\\tOverlap={overlap}\"):\n",
    "                    k = round(k, 2)\n",
    "                    dir = f\"{network_type}_n={n}_k={k}\"\n",
    "\n",
    "                    matchings = []\n",
    "                    for file in os.listdir(os.path.join(config.SYNTHETIC_NET_PATH, network_type, dir)):\n",
    "                        if \"base\" in file or f\"overlap={overlap}.txt\" in file:\n",
    "                            graph = read_network(os.path.join(config.SYNTHETIC_NET_PATH, network_type, dir, file), n)\n",
    "                            matching = Matching(graph)\n",
    "                            matching.HK_algorithm()\n",
    "                            matchings.append(matching)\n",
    "                    \n",
    "                    multi_matching = MultiMatching(matchings)\n",
    "                    multi_matching_rsuu = copy.deepcopy(multi_matching)\n",
    "                    multi_matching_glde = copy.deepcopy(multi_matching)\n",
    "                    multi_matching_ilp = copy.deepcopy(multi_matching)\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    pre_diff_mds_1_size, pre_diff_mds_2_size, pre_union_size, union_size, average_depth = multi_matching.CLAPS()\n",
    "                    end_time = time.time()\n",
    "                    time_clap_s = end_time - start_time\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "                    union_size_rsuu = multi_matching_rsuu.RSU()\n",
    "                    end_time = time.time()\n",
    "                    time_rsuu = end_time - start_time\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    union_size_glde = multi_matching_glde.CLAPG()\n",
    "                    end_time = time.time()\n",
    "                    time_glde = end_time - start_time\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    union_size_ilp = multi_matching_ilp.ILP_exact(budget_mode=\"auto\")\n",
    "                    end_time = time.time()\n",
    "                    time_ilp = end_time - start_time\n",
    "\n",
    "                    with open(output_file_name, \"a\", encoding=\"utf-8\") as output_file:\n",
    "                        output_file.write(\",\".join([\n",
    "                            f\"{network_type}+{network_type}\", str(n), str(k), str(overlap),\n",
    "                            str(len(matchings[0].driver_nodes)), str(len(matchings[1].driver_nodes)), \n",
    "                            str(pre_diff_mds_1_size), str(pre_diff_mds_2_size), str(pre_union_size), \n",
    "                            str(union_size), str(union_size_rsuu), str(union_size_glde), str(union_size_ilp), \n",
    "                            str(average_depth),\n",
    "                            str(time_clap_s),str(time_rsuu), str(time_glde), str(time_ilp)\n",
    "                        ]) + \"\\n\")\n",
    "\n",
    "optimization_proportion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
