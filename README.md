# OCMN: Overlapping Community Matching in Networks

This repository contains the official implementation for the paper "Overlapping Community Matching in Networks". It provides the source code for the proposed algorithms (CLAPS, CLAPG) and other baseline methods for solving the Overlapping Community Matching problem.

## File Structure

The project is organized as follows:

```
.
├── assets/
│   ├── log/                  # Log files for debugging and tracking
│   ├── net/                  # Network datasets
│   │   ├── real/             # Real-world network datasets
│   │   └── synthetic/        # Synthetic networks generated by the model
│   └── result/               # Experiment results
│       ├── figure/           # Figures for visualization
│       └── *.csv             # Raw results in CSV format
├── utils/
│   ├── generator.py          # Generates synthetic networks (ER, SF)
│   ├── plot.py               # Helper functions for plotting and visualization
│   └── utils.py              # Utility functions (e.g., reading networks)
├── scripts/
│   ├── experiments.ipynb     # Jupyter notebook for running experiments
│   ├── real_networks.ipynb   # Notebook for experiments on real-world networks
│   └── results.ipynb         # Notebook for visualizing and analyzing results
├── config.py                 # Configuration file for project settings
├── main.py                   # Main script to run and compare algorithms
├── matching.py               # Core implementation of all matching algorithms
└── README.md                 # This file
```

## Quick Start

### Prerequisites

- Python 3.8+
- Required packages can be installed via pip:
  ```bash
  pip install networkx numpy pandas matplotlib
  ```

### Running the Code

You can run a simple test case to compare all implemented algorithms by executing `main.py`:

```bash
python main.py
```

This script will:
1. Generate a synthetic two-layer network.
2. Run CLAPS, RSU, CLAPG, MI, and ILP algorithms.
3. Print the results and execution time for each algorithm.

You can modify the network parameters (number of nodes `n`, average degree `k`) at the bottom of `main.py`.

## How to Use

### 1. Read or Generate a Network

#### Generate a Synthetic Network
You can use the generators in `utils/generator.py` to create synthetic networks. The following example shows how to generate a two-layer Scale-Free (SF) network.

```python
from utils.generator import SFGenerator

# Initialize a generator for a network with 1000 nodes and an average degree of 4
generator = SFGenerator(n=1000, k=4)

# Generate a 2-layer network
graphs = generator.generate_networks(num_layers=2)
```
Supported generators include `SFGenerator` (Scale-Free), `ERGenerator` (Erdős-Rényi), and `BAGenerator` (Barabási-Albert).

#### Read a Network from File
You can read a network from an edge list file using the `read_network` utility.

```python
from utils.utils import read_network

# Read a network with 100 nodes from a file
graph = read_network(file_path="assets/net/real/SomeNet.txt", n=100)
```

> **Note:** The `assets/net/test` directory contains copies of the real-world network data used in our paper, as well as various synthetic test networks with different numbers of nodes and average degrees. You are encouraged to use these files for testing. For example:
> ```bash
> python main.py --files assets/net/test/Cannes_MT.txt assets/net/test/Cannes_RT.txt -n 36
> ```
> **Important:** When reading any network from a file, you **must** specify the total number of nodes `n` using the `-n` argument. This is crucial for ensuring data consistency across layers, especially for nodes that might be isolated (have no edges) in one layer but are present in another. Failing to specify the correct total `n` can lead to incorrect graph structures and runtime errors, as isolated nodes are inherently driver nodes and must be included in the analysis.

### 2. Run Matching Algorithms

The core logic for all algorithms is in `matching.py`. To run an algorithm, you first need to create `Matching` objects for each network layer and then a `MultiMatching` object to manage them.

```python
import copy
from matching import Matching, MultiMatching

# Assuming 'graphs' is a list of networkx.Graph objects
matchings = []
for g in graphs:
    matching = Matching(g)
    matching.HK_algorithm()  # Find an initial maximum matching
    matchings.append(matching)

# Create a MultiMatching object for algorithm comparison
clap_s_matching = MultiMatching(matchings)
rsu_matching = copy.deepcopy(clap_s_matching)
glde_matching = copy.deepcopy(clap_s_matching)

# Run different algorithms
print("Running CLAPS...")
clap_s_matching.CLAPS()

print("Running RSU...")
rsu_matching.RSU()

print("Running CLAPG...")
glde_matching.CLAPG()
```

The available algorithms in `MultiMatching` are:
- `CLAPS()`: Our proposed core algorithm.
- `CLAPG()`: Our proposed greedy algorithm.
- `RSU()`: A baseline algorithm.
- `MI_exact()`: An exact algorithm based on maximum independent set.
- `ILP_exact()`: An exact algorithm using Integer Linear Programming.

### 3. Algorithm Comparison

The `main.py` script provides a template for comparing the performance and execution time of different algorithms on the same network. You can adapt its `test()` function for your own needs.

## Experiment Reproduction and Visualization

The `scripts/` directory contains Jupyter notebooks to reproduce the experiments from our paper and visualize the results.

- **`experiments.ipynb`**: This notebook contains the code to run experiments on synthetic networks, varying parameters such as network size, density, and overlap. It saves the results to the `assets/result/` directory.
- **`real_networks.ipynb`**: This notebook is dedicated to running experiments on the real-world network datasets located in `assets/net/real/`.
- **`results.ipynb`**: Use this notebook to load the `.csv` files from the results directory and generate the figures and tables presented in the paper. It relies on `utils/plot.py` for plotting functions.
